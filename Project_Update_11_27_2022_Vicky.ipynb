{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49982f1",
   "metadata": {},
   "source": [
    "# The House Price Prediction\n",
    "## Team 4: Vicky Van Der Wagt, Halee Staggs, Bethany Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83ae80",
   "metadata": {},
   "source": [
    "Changes 11/19/22\n",
    "    \n",
    "*  Inserted data cleaning setps\n",
    "* Although earlier we talked about replacing missing values with item that correlates to it the most, after looking at graphs, they do not have clear linear relationships. Therefore, I used the averages for now. Will read more projects to see what else they did. \n",
    "* Also added discretization (5 categories for longitude, 3 categories for latitude). Then added a loc_cat column (location category) which has the concatenated values. Clear relationship between loc_cat and price\n",
    "* For duplicate ids, removed the oldest entry and only kept the most recent one. \n",
    "* Removed outliers using quartiles in iqr for sqft_living and sqft_lot since those had the most extreme values. Also concluded the 33 bedroom entry was a mistake, as the square footage was less than 2000(definitely could not fit 33 bedrooms). Therefore, replaced it same method as other bedrooms (with average bedrooms). \n",
    "* Holding off on deleting most columns until we decide what is relevant to our models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba245b",
   "metadata": {},
   "source": [
    "Changes 11/24/22\n",
    "1. Remove outliers from price. \n",
    "\n",
    "2. Updated \"yr_renovated\" to Yes/No. Only ~900 with yes. \n",
    "\n",
    "3. Converted year built to age. Added column.\n",
    "\n",
    "4. Normalized outcome variable with square root transformation instead of log. Original data was positively skewed, and then log transformed was negatively skewed so log was not the right method.  \n",
    "\n",
    "5. Reduced dimensions for lat/long location groups. Added a 3X3 grid to compare. There were 3 long/lat groups that only ontained 1 house. By reducing dimensions, it grouped everything so each area is better represented. When looking at the bar chart, there are 4 distinct price levels. I think we can reduce the location dimensions even further into 3 groups (North, Central, South). The prices differences go North-South more so than East-West. This will help with final model to reduce number of dummy variables.\n",
    "\n",
    "6. Updated numerical/categorical/ordinal lists of variables. \n",
    "\n",
    "7. **Most of our variables are discrete. We cannot compute mean and standard deviation for them. Udated missing values to fill with median. Use PMF for distributions. Median house prices for Washington state listed here: https://ofm.wa.gov/washington-data-research/statewide-data/washington-trends/economic-trends/median-home-price. 2014 = 267,600 and 2015 = 289,100. Maybe we can use this as some sort of cut-off. Add binary variable of above median or below median?? Combine with location?? ** \n",
    "\n",
    "8. Ordinal variables can be used in correlations. Added them to the numerical correlation matrix. However, ordinal data is not 100% valid to use in linear regression. Grade is correlated with price, but not rating. \n",
    "\n",
    "9. We cannot use price/sqft for a predictor variable. This would mean that we are using a dimension of our dependent variable inside our model, which is invalid. Just stick to continuous measurement of sqft living separate from price. Commented out this section and updated price vs. price/log histogram display.  \n",
    "\n",
    "10. Tested Spearman rank correlation between ordinal variables (grade and rating). No relationship found. \n",
    "\n",
    "11. Added Chi-Square tests for categorical variables to test relationship with price, location, and other categories. Used log-normal price data for test. Turned \"price\" into categorical with 6 bins to test relationships. 6 bins = 3 SD on each side, so basically 100% of data. The year 2014 contains months from only May-Dec, and 2015 contains months from January to May. This means we cannot use \"year\" for any meaningful comparison. Together they create a full year of data. Confirmed with x2 test. Also tested month on its own. Month shows a difference in x2 test. Formal test of Vicky's percentage differences.  \n",
    "\n",
    "12. Normalized sqft_living before modeling with square root transformation.\n",
    "\n",
    "13. Testing relationship between all predictor variables with x2 conversion. \n",
    "\n",
    "14. Final proposed predictor variables: sqft_living - log, location, yr_sold.\n",
    "\n",
    "15. Ran multinomial linear regression. price_log ~ sqft_log + locations(dummy) + yr_sold + e\n",
    "\n",
    "16. Added data visualizations.\n",
    "\n",
    "17. Added conclusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67484b0a",
   "metadata": {},
   "source": [
    "Changes 11/27/22\n",
    "\n",
    "1. Added 'season' column derived from the month column. (Under Feature Construction and Discretization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877283d",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723efbe",
   "metadata": {},
   "source": [
    "## 2. Data Importing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f9852",
   "metadata": {},
   "source": [
    "* Import dataset and describe characteristics such as dimensions, data types, file types, and import methods used\n",
    "* Clean, wrangle, and handle missing data\n",
    "* Transform data appropriately using techniques such as aggregation, normalization, and feature construction\n",
    "* Reduce redundant data and perform need-based discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839556e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace1d95",
   "metadata": {},
   "source": [
    "### Import data, data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6bc7036",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Halee\\\\Downloads\\\\house_sales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-345b97115811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\Halee\\Downloads\\house_sales.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Halee\\\\Downloads\\\\house_sales.csv'"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\Halee\\Downloads\\house_sales.csv')\n",
    "#dataset = pd.read_csv(r'house_sales.csv')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6903c8e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\halee\\\\Downloads\\\\house_sales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ff21728dd8d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\halee\\Downloads\\house_sales.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\halee\\\\Downloads\\\\house_sales.csv'"
     ]
    }
   ],
   "source": [
    "dataset_original = pd.read_csv(r'C:\\Users\\halee\\Downloads\\house_sales.csv')\n",
    "#dataset_original = pd.read_csv(r'house_sales.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ff2df",
   "metadata": {},
   "source": [
    "### Clean and Handle Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1a7f5",
   "metadata": {},
   "source": [
    "#### Clean up date and convert to date_time unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cebed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dataset['date'] = pd.to_datetime(dataset['date'], format='%Y/%m/%d')\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6a3d7",
   "metadata": {},
   "source": [
    "#### Add Season column from months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6080a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50102258",
   "metadata": {},
   "source": [
    "#### Remove values that don't reflect normal houses, that have zero bedrooms, or not full bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe55f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#am also considering filling them out with average, but for now, this. \n",
    "dataset = dataset[dataset['bedrooms']!=0]\n",
    "dataset = dataset[dataset['bathrooms'] > 0.5]\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32a7c7",
   "metadata": {},
   "source": [
    "#### Exploring Potential Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore mean and std\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3067e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['price'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c714703",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sqft_lot'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sqft_living'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cf8bd7",
   "metadata": {},
   "source": [
    "### Check and Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8989fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick way to clean data, will be replaced later\n",
    "#dataset = houses.dropna()\n",
    "\n",
    "#Removing houses that have zero bedrooms or bathrooms; does not reflect typical home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6523384",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30459af9",
   "metadata": {},
   "source": [
    "#### Fill in missing values in the sqft_living column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ff66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft_above = dataset['sqft_above']\n",
    "sqft_basement = dataset['sqft_basement']\n",
    "sqft_living = sqft_above + sqft_basement\n",
    "dataset.loc[dataset['sqft_living'].isnull(),'sqft_living']=sqft_living\n",
    "\n",
    "sns.scatterplot(data=dataset, x=\"sqft_living\", y=\"sqft_living15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c86a09",
   "metadata": {},
   "source": [
    "#### Fill in missing values in the bedrooms column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which value correlates most (sqft_living)\n",
    "#dataset.corr()\n",
    "#sns.scatterplot(data=dataset, x=\"bedrooms\", y=\"sqft_living\")\n",
    "\n",
    "\n",
    "#after viewing the scatterplot, can be seen that the relationship is not quite linear.\n",
    "#updated to median\n",
    "bedrooms_avg = dataset['bedrooms'].median()\n",
    "dataset.loc[dataset['bedrooms'].isnull(),'bedrooms']=bedrooms_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8f50e",
   "metadata": {},
   "source": [
    "#### Fill in missing values in the sqft_lot category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a15819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#even though high correlation coefficient, no clear relationship. therefore, also using averages.\n",
    "\n",
    "sqft_lot_avg = dataset['sqft_lot'].median()\n",
    "dataset.loc[dataset['sqft_lot'].isnull(),'sqft_lot']=sqft_lot_avg\n",
    "\n",
    "sns.scatterplot(data=dataset, x=\"sqft_lot15\", y=\"sqft_lot\")\n",
    "#new pattern popped out showing something for 15,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac7c23",
   "metadata": {},
   "source": [
    "#### Fill in missing values in the bathrooms column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated to median\n",
    "bathrooms_avg = dataset['bathrooms'].median()\n",
    "dataset.loc[dataset['bathrooms'].isnull(),'bathrooms']=bathrooms_avg\n",
    "\n",
    "sns.scatterplot(data=dataset, x=\"bathrooms\", y=\"sqft_living\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e1e3e3",
   "metadata": {},
   "source": [
    "#### Removing outliers \n",
    "* After doing df.describe(), we can see that the biggest outliers are in the bedroom, sqft_lot, and sqft_living categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highest bedroom value was 33. After further investigation, looks like data entry mistake. fill with avg\n",
    "dataset['bedrooms'] = dataset['bedrooms'].replace([33],bedrooms_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da74f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed outliers with large sqft_lots\n",
    "q1 = dataset['sqft_lot'].quantile(.25)\n",
    "q2 = dataset['sqft_lot'].quantile(.5)\n",
    "q3 = dataset['sqft_lot'].quantile(.75)\n",
    "q4 = dataset['sqft_lot'].quantile(.1)\n",
    "iqr = q3 - q1\n",
    "\n",
    "#instead of doing standard 1.5iqr, did 1.65 so we did not lose too much data\n",
    "#upperlimit = q3 + (1.65*iqr)\n",
    "#lowerlimit = q1 - (1.65*iqr)\n",
    "\n",
    "#tested with 1.5\n",
    "upperlimit = q3 + (1.5*iqr)\n",
    "lowerlimit = q1 - (1.5*iqr)\n",
    "\n",
    "dataset = dataset[dataset['sqft_lot']<upperlimit]\n",
    "#lowerlimit is less than zero so don't need to filter because no occurence of negative values\n",
    "\n",
    "dataset['sqft_sqrt'] = np.sqrt(dataset['sqft_living'])\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Boxplot')\n",
    "sns.boxplot(data = dataset[['sqft_sqrt']])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Distribution of Sqft_Sqrt')\n",
    "sns.distplot(dataset['sqft_sqrt'])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title('Distribution of Sqft_Living')\n",
    "sns.distplot(dataset['sqft_living'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed outliers in sqft_living after log transformation\n",
    "q1 = dataset['sqft_living'].quantile(.25)\n",
    "q2 = dataset['sqft_living'].quantile(.5)\n",
    "q3 = dataset['sqft_living'].quantile(.75)\n",
    "q4 = dataset['sqft_living'].quantile(.1)\n",
    "\n",
    "#iqr = q3 - q1\n",
    "\n",
    "#instead of doing standard 1.5iqr, did 1.65 so we did not lose too much data\n",
    "#upperlimit = q3 + (1.6*iqr)\n",
    "#lowerlimit = q1 - (1.6*iqr)\n",
    "\n",
    "#tested with 1.5\n",
    "#upperlimit = q3 + (1.5*iqr)\n",
    "#upperlimit\n",
    "#lowerlimit = q1 - (1.5*iqr)\n",
    "#lowerlimit\n",
    "\n",
    "#dataset['price_sqrt'] = np.sqrt(dataset['price'])\n",
    "\n",
    "\n",
    "#dataset = dataset[dataset['sqft_living']<upperlimit]\n",
    "#sns.scatterplot(data=dataset, x=\"sqft_living\", y=\"sqft_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315951e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed outliers in price\n",
    "q1 = dataset['price'].quantile(.25)\n",
    "q2 = dataset['price'].quantile(.5)\n",
    "q3 = dataset['price'].quantile(.75)\n",
    "q4 = dataset['price'].quantile(.1)\n",
    "\n",
    "iqr = q3 - q1\n",
    "\n",
    "#instead of doing standard 1.5iqr, did 1.65 so we did not lose too much data\n",
    "#upperlimit = q3 + (1.6*iqr)\n",
    "#lowerlimit = q1 - (1.6*iqr)\n",
    "\n",
    "#tested with 1.5\n",
    "upperlimit = q3 + (1.5*iqr)\n",
    "lowerlimit = q1 - (1.5*iqr)\n",
    "\n",
    "\n",
    "dataset = dataset[dataset['price']<upperlimit]\n",
    "\n",
    "dataset['price_sqrt'] = np.sqrt(dataset['price'])\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Boxplot')\n",
    "sns.boxplot(data = dataset[['price_sqrt']])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Distribution of Price_Sqrt')\n",
    "sns.distplot(dataset['price_sqrt'])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title('Distribution of Price')\n",
    "sns.distplot(dataset['price'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60308ef3",
   "metadata": {},
   "source": [
    "### Drop redundant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e6c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ignore the warning message\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#dropping the earliest entry of each duplicate ID \n",
    "dataset.sort_values(by=['id', 'date'], inplace=True)\n",
    "#keeping the entry with the most recent date\n",
    "dataset = dataset.drop_duplicates(subset=['id'], keep='last')\n",
    "#houses.drop(['id'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7c59c",
   "metadata": {},
   "source": [
    "### Feature Construction and Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e129ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>yr_sold</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "2  5631500400  20150225T000000  180000.0       2.0       1.00        770.0   \n",
       "3  2487200875  20141209T000000  604000.0       4.0       3.00       1960.0   \n",
       "4  1954400510  20150218T000000  510000.0       3.0       2.00       1680.0   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  yr_built  yr_renovated  zipcode  \\\n",
       "0    5650.0     1.0           0     0  ...      1955             0    98178   \n",
       "1    7242.0     2.0           0     0  ...      1951          1991    98125   \n",
       "2   10000.0     1.0           0     0  ...      1933             0    98028   \n",
       "3    5000.0     1.0           0     0  ...      1965             0    98136   \n",
       "4    8080.0     1.0           0     0  ...      1987             0    98074   \n",
       "\n",
       "       lat     long  sqft_living15  sqft_lot15  yr_sold  month_sold  season  \n",
       "0  47.5112 -122.257           1340        5650     2014          10  Summer  \n",
       "1  47.7210 -122.319           1690        7639     2014          12      12  \n",
       "2  47.7379 -122.233           2720        8062     2015           2       2  \n",
       "3  47.5208 -122.393           1360        5000     2014          12      12  \n",
       "4  47.6168 -122.045           1800        7503     2015           2       2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f9a96",
   "metadata": {},
   "source": [
    "#### Add columns for year sold, month sold, and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b757df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>yr_sold</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420.0</td>\n",
       "      <td>101930.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6561</td>\n",
       "      <td>-122.005</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008000270</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>9711.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2414600126</td>\n",
       "      <td>20150415T000000</td>\n",
       "      <td>229500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>7470.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5123</td>\n",
       "      <td>-122.337</td>\n",
       "      <td>1780</td>\n",
       "      <td>8113</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3793500160</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>323000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>6560.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.3684</td>\n",
       "      <td>-122.031</td>\n",
       "      <td>2390</td>\n",
       "      <td>7570</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1736800520</td>\n",
       "      <td>20150403T000000</td>\n",
       "      <td>662500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9796.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98007</td>\n",
       "      <td>47.6007</td>\n",
       "      <td>-122.145</td>\n",
       "      <td>2210</td>\n",
       "      <td>8925</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9212900260</td>\n",
       "      <td>20140527T000000</td>\n",
       "      <td>468000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6900</td>\n",
       "      <td>-122.292</td>\n",
       "      <td>1330</td>\n",
       "      <td>6000</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>114101516</td>\n",
       "      <td>20140528T000000</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19901.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7558</td>\n",
       "      <td>-122.229</td>\n",
       "      <td>1780</td>\n",
       "      <td>12697</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6054650070</td>\n",
       "      <td>20141007T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>9680.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6127</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1370</td>\n",
       "      <td>10208</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1175000570</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>530000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6700</td>\n",
       "      <td>-122.394</td>\n",
       "      <td>1360</td>\n",
       "      <td>4850</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9297300055</td>\n",
       "      <td>20150124T000000</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5714</td>\n",
       "      <td>-122.375</td>\n",
       "      <td>2140</td>\n",
       "      <td>4000</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1875500060</td>\n",
       "      <td>20140731T000000</td>\n",
       "      <td>395000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>14040.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>98019</td>\n",
       "      <td>47.7277</td>\n",
       "      <td>-121.962</td>\n",
       "      <td>1890</td>\n",
       "      <td>14018</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6865200140</td>\n",
       "      <td>20140529T000000</td>\n",
       "      <td>485000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1916</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6648</td>\n",
       "      <td>-122.343</td>\n",
       "      <td>1610</td>\n",
       "      <td>4300</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16000397</td>\n",
       "      <td>20141205T000000</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>9850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>98002</td>\n",
       "      <td>47.3089</td>\n",
       "      <td>-122.210</td>\n",
       "      <td>1060</td>\n",
       "      <td>5095</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7983200060</td>\n",
       "      <td>20150424T000000</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>9774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3343</td>\n",
       "      <td>-122.306</td>\n",
       "      <td>1280</td>\n",
       "      <td>8850</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0   7129300520  20141013T000000   221900.0       3.0       1.00       1180.0   \n",
       "1   6414100192  20141209T000000   538000.0       3.0       2.25       2570.0   \n",
       "2   5631500400  20150225T000000   180000.0       2.0       1.00        770.0   \n",
       "3   2487200875  20141209T000000   604000.0       4.0       3.00       1960.0   \n",
       "4   1954400510  20150218T000000   510000.0       3.0       2.00       1680.0   \n",
       "5   7237550310  20140512T000000  1225000.0       4.0       4.50       5420.0   \n",
       "6   1321400060  20140627T000000   257500.0       3.0       2.25       1715.0   \n",
       "7   2008000270  20150115T000000   291850.0       3.0       1.50       1060.0   \n",
       "8   2414600126  20150415T000000   229500.0       3.0       1.00       1780.0   \n",
       "9   3793500160  20150312T000000   323000.0       3.0       2.50       1890.0   \n",
       "10  1736800520  20150403T000000   662500.0       3.0       2.50          NaN   \n",
       "11  9212900260  20140527T000000   468000.0       2.0       1.00       1160.0   \n",
       "12   114101516  20140528T000000   310000.0       3.0       1.00          NaN   \n",
       "13  6054650070  20141007T000000   400000.0       3.0       1.75       1370.0   \n",
       "14  1175000570  20150312T000000   530000.0       5.0       2.00       1810.0   \n",
       "15  9297300055  20150124T000000   650000.0       4.0       3.00       2950.0   \n",
       "16  1875500060  20140731T000000   395000.0       3.0       2.00       1890.0   \n",
       "17  6865200140  20140529T000000   485000.0       4.0       1.00       1600.0   \n",
       "18    16000397  20141205T000000   189000.0       NaN       1.00       1200.0   \n",
       "19  7983200060  20150424T000000   230000.0       3.0       1.00       1250.0   \n",
       "\n",
       "    sqft_lot  floors  waterfront  view  ...  yr_built  yr_renovated  zipcode  \\\n",
       "0     5650.0     1.0           0     0  ...      1955             0    98178   \n",
       "1     7242.0     2.0           0     0  ...      1951          1991    98125   \n",
       "2    10000.0     1.0           0     0  ...      1933             0    98028   \n",
       "3     5000.0     1.0           0     0  ...      1965             0    98136   \n",
       "4     8080.0     1.0           0     0  ...      1987             0    98074   \n",
       "5   101930.0     1.0           0     0  ...      2001             0    98053   \n",
       "6     6819.0     2.0           0     0  ...      1995             0    98003   \n",
       "7     9711.0     1.0           0     0  ...      1963             0    98198   \n",
       "8     7470.0     1.0           0     0  ...      1960             0    98146   \n",
       "9     6560.0     2.0           0     0  ...      2003             0    98038   \n",
       "10    9796.0     1.0           0     0  ...      1965             0    98007   \n",
       "11    6000.0     1.0           0     0  ...      1942             0    98115   \n",
       "12   19901.0     1.5           0     0  ...      1927             0    98028   \n",
       "13    9680.0     1.0           0     0  ...      1977             0    98074   \n",
       "14    4850.0     1.5           0     0  ...      1900             0    98107   \n",
       "15    5000.0     2.0           0     3  ...      1979             0    98126   \n",
       "16   14040.0     2.0           0     0  ...      1994             0    98019   \n",
       "17    4300.0     1.5           0     0  ...      1916             0    98103   \n",
       "18    9850.0     1.0           0     0  ...      1921             0    98002   \n",
       "19    9774.0     1.0           0     0  ...      1969             0    98003   \n",
       "\n",
       "        lat     long  sqft_living15  sqft_lot15  yr_sold  month_sold  season  \n",
       "0   47.5112 -122.257           1340        5650     2014          10    Fall  \n",
       "1   47.7210 -122.319           1690        7639     2014          12  Winter  \n",
       "2   47.7379 -122.233           2720        8062     2015           2  Winter  \n",
       "3   47.5208 -122.393           1360        5000     2014          12  Winter  \n",
       "4   47.6168 -122.045           1800        7503     2015           2  Winter  \n",
       "5   47.6561 -122.005           4760      101930     2014           5  Spring  \n",
       "6   47.3097 -122.327           2238        6819     2014           6  Summer  \n",
       "7   47.4095 -122.315           1650        9711     2015           1  Winter  \n",
       "8   47.5123 -122.337           1780        8113     2015           4  Spring  \n",
       "9   47.3684 -122.031           2390        7570     2015           3  Spring  \n",
       "10  47.6007 -122.145           2210        8925     2015           4  Spring  \n",
       "11  47.6900 -122.292           1330        6000     2014           5  Spring  \n",
       "12  47.7558 -122.229           1780       12697     2014           5  Spring  \n",
       "13  47.6127 -122.045           1370       10208     2014          10    Fall  \n",
       "14  47.6700 -122.394           1360        4850     2015           3  Spring  \n",
       "15  47.5714 -122.375           2140        4000     2015           1  Winter  \n",
       "16  47.7277 -121.962           1890       14018     2014           7  Summer  \n",
       "17  47.6648 -122.343           1610        4300     2014           5  Spring  \n",
       "18  47.3089 -122.210           1060        5095     2014          12  Winter  \n",
       "19  47.3343 -122.306           1280        8850     2015           4  Spring  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['yr_sold'] = pd.DatetimeIndex(dataset['date']).year\n",
    "dataset['month_sold'] = pd.DatetimeIndex(dataset['date']).month\n",
    "\n",
    "\n",
    "dataset['month_sold'] = dataset['month_sold'].astype(str)\n",
    "look_up = {'1': 'Winter', '2': 'Winter', '3': 'Spring', '4': 'Spring', '5': 'Spring', \n",
    "           '6': 'Summer', '7': 'Summer', '8': 'Summer', '9': 'Fall', '10': 'Fall', '11': 'Fall', '12': 'Winter'}\n",
    "\n",
    "dataset['season'] = dataset['month_sold'].apply(lambda x: look_up[x])\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1ec7e",
   "metadata": {},
   "source": [
    "**Add column to change year renovated to binary variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1540ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update dataset to Yes/No for renovated\n",
    "dataset[\"renovate\"] = pd.cut(dataset[\"yr_renovated\"],2,labels = ['No','Yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update year built to age\n",
    "#import datetime\n",
    "#t1 = dataset['yr_sold']\n",
    "#t2 = dataset['yr_built']\n",
    "#house_age = t1 - t2\n",
    "#dataset['house_age'] = house_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60589a74",
   "metadata": {},
   "source": [
    "#### Generate Categories for lat, long, and latitude + longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d03782",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['lat_cat'] = pd.cut(dataset['lat'],3,labels = ['south', 'central', 'north'])\n",
    "dataset.head()\n",
    "\n",
    "dataset['long_cat'] = pd.cut(dataset['long'],5,labels = ['west', 'midwest', 'central', 'mideast', 'east'])\n",
    "dataset.head()\n",
    "\n",
    "lat_cat = dataset['lat_cat']\n",
    "long_cat = dataset['long_cat']\n",
    "\n",
    "#aggregate the latitude and longitude together for a final location category\n",
    "dataset['loc_cat'] = dataset[['lat_cat', 'long_cat']].agg('-'.join, axis=1)\n",
    "\n",
    "location_category = dataset['loc_cat']\n",
    "price = dataset['price']\n",
    "#plot just to see\n",
    "location_barplot = sns.barplot(x=location_category, y=price)\n",
    "#makes it so the labels don't run into each other\n",
    "location_barplot.set_xticklabels(location_barplot.get_xticklabels(), rotation = 45, horizontalalignment = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b126269",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['lat_cat'] = pd.cut(dataset['lat'],3,labels = ['south', 'central', 'north'])\n",
    "dataset.head()\n",
    "\n",
    "dataset['long_cat'] = pd.cut(dataset['long'],3,labels = ['west', 'central', 'east'])\n",
    "dataset.head()\n",
    "\n",
    "lat_cat = dataset['lat_cat']\n",
    "long_cat = dataset['long_cat']\n",
    "\n",
    "#aggregate the latitude and longitude together for a final location category\n",
    "dataset['loc_cat'] = dataset[['lat_cat', 'long_cat']].agg('-'.join, axis=1)\n",
    "\n",
    "\n",
    "location_category = dataset['loc_cat']\n",
    "price = dataset['price']\n",
    "#plot just to see\n",
    "location_barplot = sns.barplot(x=location_category, y=price)\n",
    "#makes it so the labels don't run into each other\n",
    "location_barplot.set_xticklabels(location_barplot.get_xticklabels(), rotation = 45, horizontalalignment = 'center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e0700",
   "metadata": {},
   "source": [
    "### Test only lattitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_category = dataset['lat_cat']\n",
    "price = dataset['price']\n",
    "#plot just to see\n",
    "location_barplot = sns.barplot(x=location_category, y=price)\n",
    "#makes it so the labels don't run into each other\n",
    "location_barplot.set_xticklabels(location_barplot.get_xticklabels(), rotation = 45, horizontalalignment = 'center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cada6f7",
   "metadata": {},
   "source": [
    "### Test only longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee651f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_category = dataset['long_cat']\n",
    "price = dataset['price']\n",
    "#plot just to see\n",
    "location_barplot = sns.barplot(x=location_category, y=price)\n",
    "#makes it so the labels don't run into each other\n",
    "location_barplot.set_xticklabels(location_barplot.get_xticklabels(), rotation = 45, horizontalalignment = 'center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f0c48",
   "metadata": {},
   "source": [
    "### Longitude as 2 categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['long_cat_2'] = pd.cut(dataset['long'],2,labels = ['west', 'east'])\n",
    "dataset.head()\n",
    "\n",
    "location_category = dataset['long_cat_2']\n",
    "price = dataset['price']\n",
    "#plot just to see\n",
    "location_barplot = sns.barplot(x=location_category, y=price)\n",
    "#makes it so the labels don't run into each other\n",
    "location_barplot.set_xticklabels(location_barplot.get_xticklabels(), rotation = 45, horizontalalignment = 'center')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac800a86",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32597c3c",
   "metadata": {},
   "source": [
    "* Identify categorical, ordinal, and numerical variables within the data\n",
    "* Provide measures of centrality and distribution with visualizations\n",
    "* Diagnose for correlations between variables and determine independent and dependent variables\n",
    "* Perform exploratory analysis in combination with visualization techniques to discover patterns and features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical, ordinal, and numerical variables within the original data\n",
    "numerical_variables = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'condition', 'grade', \n",
    "                      'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15']\n",
    "ordinal_variables = ['condition', 'grade']\n",
    "categorical_variables = ['date', 'waterfront', 'view', 'zipcode', 'lat', 'long']\n",
    "\n",
    "\n",
    "discrete_vars = ['price', 'bedrooms', 'bathrooms', 'floors', 'condition', 'grade',\n",
    "                 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_living15']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403434c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated lists of variables\n",
    "\n",
    "num_vars_update = ['price_sqrt', 'bedrooms', 'bathrooms', 'sqft_sqrt', \n",
    "                       'floors', 'condition', 'grade', 'yr_built']\n",
    "\n",
    "cat_var_update = ['lat_cat', 'long_cat', 'loc_cat', 'yr_sold', 'month_sold', 'renovate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42220465",
   "metadata": {},
   "source": [
    "### Statistical and Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db098a",
   "metadata": {},
   "source": [
    "From the statistical analysis table and the correlation heatmap, we see:\n",
    "* some redundant variables, such as 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15', they can be removed.\n",
    "* The house with 33 bedrooms should be treated as outlier. Therefore, it can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_subset_1 = dataset[numerical_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the statistics for the numerical variables\n",
    "round(numerical_subset_1.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlation coefficients of among the numerical variables\n",
    "round(numerical_subset_1.corr(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ca765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for correlations from original data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Heat Map of Correlation Coefficients\", fontsize=16)\n",
    "sns.heatmap(numerical_subset_1.corr(), cmap = 'coolwarm', fmt = '.1f', linewidths = 1, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e206cca",
   "metadata": {},
   "source": [
    "## **Update variables and redo matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000b000e",
   "metadata": {},
   "source": [
    "### Adding New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two new columns 'price_per_sqft' and 'price_log' to facilitate analysis\n",
    "#houses['price_per_sqft'] = houses['price'] / houses['sqft_living']\n",
    "#numerical_subset['price_per_sqft'] = houses['price'] / houses['sqft_living']\n",
    "#numerical_subset['price_log'] = np.log(houses['price'])\n",
    "#houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset numerical fields\n",
    "numerical_subset_2 = dataset[num_vars_update]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the statistics for the numerical variables\n",
    "round(numerical_subset_2.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee51729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlation coefficients of among the numerical variables\n",
    "round(numerical_subset_2.corr(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Heat Map of Correlation Coefficients\", fontsize=16)\n",
    "sns.heatmap(numerical_subset_2.corr(), cmap = 'coolwarm', fmt = '.1f', linewidths = 1, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec8c17",
   "metadata": {},
   "source": [
    "### Data Wrangling (Will be merged or replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some redundant variables\n",
    "#warnings.filterwarnings('ignore')\n",
    "#dataset.drop(['sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15'], axis=1, inplace = True)\n",
    "#numerical_subset.drop(['sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15'], axis=1, inplace = True)\n",
    "\n",
    "# Drop the outlier with the extreme number of bedrooms.tagged this out because we \n",
    "#already changed it to 3\n",
    "#dataset.drop(dataset[dataset.bedrooms > 20].index, inplace = True)\n",
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82a636",
   "metadata": {},
   "source": [
    "### Redo Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626aba43",
   "metadata": {},
   "source": [
    "### Histogram Distribution of the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bcd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Prices into a new variable\n",
    "prices = dataset['price']\n",
    "\n",
    "# Define column lists for plotting\n",
    "bar_cols = ['view', 'waterfront', 'condition', 'grade', 'bedrooms', 'bathrooms']\n",
    "scatter_cols = ['yr_built', 'yr_renovated', 'sqft_living', 'sqft_lot', 'bathrooms', 'bedrooms', 'grade', 'floors']\n",
    "pair_cols = ['sqft_living', 'sqft_lot', 'grade', 'condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Histogram for Prices\n",
    "plt.figure(1)\n",
    "plt.title('Distribution of Prices')\n",
    "sns.distplot(prices, kde=False, fit=stats.norm)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Distribution of Price Log')\n",
    "sns.distplot(dataset['price_log'], kde=False, fit=stats.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ea940",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.title('Distribution of Sqft_Living15')\n",
    "sns.distplot(dataset['sqft_living15'])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Distribution of Sqft_Living')\n",
    "sns.distplot(dataset['sqft_living'])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title('Distribution of Sqft_Lot15')\n",
    "sns.distplot(dataset['sqft_lot15'], kde=False, fit=stats.norm)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.title('Distribution of Sqft_Lot')\n",
    "sns.distplot(dataset['sqft_lot'], kde=False, fit=stats.norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58f279",
   "metadata": {},
   "source": [
    "### Distribution Analysis with Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1200b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Boxplot')\n",
    "sns.boxplot(data = dataset[['price_log']])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Boxplots')\n",
    "sns.boxplot(data = dataset[['bedrooms', 'bathrooms', 'floors', 'condition', 'grade']])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title('Boxplots')\n",
    "sns.boxplot(data = dataset[['sqft_living']])\n",
    "\n",
    "plt.figure(4)\n",
    "plt.title('Boxplots')\n",
    "sns.boxplot(data = dataset[['sqft_lot']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a316c",
   "metadata": {},
   "source": [
    "### Bar Plots for Categorical and Discrete Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plots\n",
    "fig,axes = plt.subplots(nrows=2,ncols=3,figsize=(18,12))\n",
    "fig.suptitle(\"Bar Graphs\",fontsize=16)\n",
    "\n",
    "for n in range(len(bar_cols)):\n",
    "    i = 0 if n < 3 else 1  \n",
    "    j = n % 3;\n",
    "    values = dataset[bar_cols[n]].value_counts()\n",
    "    pd.Series.sort_index(values, inplace=True)\n",
    "    indexes = list(values.index)\n",
    "    axes[i][j].bar(indexes, values)\n",
    "    axes[i][j].set_xlabel(bar_cols[n])\n",
    "    \n",
    "axes[0][0].set_ylabel(\"Number of Houses\")\n",
    "axes[1][0].set_ylabel(\"Number of Houses\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e24528",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18, 6))\n",
    "values = dataset['zipcode'].value_counts()\n",
    "pd.Series.sort_index(values, inplace=True)\n",
    "indexes = list(values.index)\n",
    "plt.bar(indexes, values)\n",
    "plt.title(\"House Distribution by Zipcode\", fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6dbfa",
   "metadata": {},
   "source": [
    "### Scatter Plots for Numerical Variables vs. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cd8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create scatter plots\n",
    "fig,axes = plt.subplots(nrows=2,ncols=4,figsize=(18,8))\n",
    "fig.suptitle(\"Features vs. Prices\",fontsize=16)\n",
    "\n",
    "for n in range(len(scatter_cols)):\n",
    "    i = 0 if n < 4 else 1  \n",
    "    j = n % 4;\n",
    "    axes[i][j].scatter(dataset[scatter_cols[n]], dataset['price_sqrt'])\n",
    "    axes[i][j].set_xlabel(scatter_cols[n])\n",
    "    \n",
    "axes[0][0].set_ylabel(\"Prices\")\n",
    "axes[1][0].set_ylabel(\"Prices\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35264b61",
   "metadata": {},
   "source": [
    "### Joint Plot to show Distribution by Latiture and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flipped the lat and long to reperesent map -v 11/19/2022\n",
    "sns.jointplot(dataset['long'], dataset['lat'], size= 8)\n",
    "\n",
    "\n",
    "#east locations are \"location\" outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c123be",
   "metadata": {},
   "source": [
    "# Ordinal Correlation & Tests of Association (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bd7a78",
   "metadata": {},
   "source": [
    "Spearmans Rank Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure of collinearity for ordinal variables\n",
    "data_ord = pd.DataFrame(dataset[ordinal_variables])\n",
    "\n",
    "scc_1, p = spearmanr(data_ord['condition'],data_ord['grade'])\n",
    "print('scc_1, p = %.3f' % scc_1)\n",
    "\n",
    "\n",
    "#weak negative correlation between each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b96c6",
   "metadata": {},
   "source": [
    "### Convert 'price_sqrt' into categorical bins for x2 testing. Bins = 6 (3 SD on each side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut dataset into 6 bins for price_log\n",
    "dataset['price_sqrt_cat'] = pd.cut(dataset['price_sqrt'], 6)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca95e43",
   "metadata": {},
   "source": [
    "### Price and lattitude location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chisq_freq_1_a = pd.crosstab(dataset['price_sqrt_cat'], \n",
    "                           #dataset['loc_cat'], \n",
    "                           #margins=True, margins_name='Total')\n",
    "#chisq_freq_1_a\n",
    "\n",
    "#run test\n",
    "#stats.chi2_contingency(chisq_freq_1_a)\n",
    "\n",
    "#not valid\n",
    "\n",
    "\n",
    "chisq_freq_1_b = pd.crosstab(dataset['price_sqrt_cat'], \n",
    "                           dataset['lat_cat'], \n",
    "                           margins=True, margins_name='Total')\n",
    "chisq_freq_1_b\n",
    "\n",
    "#run test\n",
    "stats.chi2_contingency(chisq_freq_1_b)\n",
    "\n",
    "#stat sig, but df and x2 are far apart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc851f",
   "metadata": {},
   "source": [
    "### Price and renovation  status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ea5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create frequency table for price bins and renovation status\n",
    "chisq_freq_2 = pd.crosstab(dataset['price_sqrt_cat'].astype('category'), \n",
    "                           dataset['renovate'], \n",
    "                           margins=True, margins_name='Total')\n",
    "#test chi square\n",
    "chisq_freq_2\n",
    "stats.chi2_contingency(chisq_freq_2)\n",
    "\n",
    "### valid relationship between renovation and price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8a1ce",
   "metadata": {},
   "source": [
    "### Price and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq_freq_3 = pd.crosstab(dataset['price_sqrt_cat'].astype('category'), \n",
    "                           dataset['yr_sold'].astype('category'), \n",
    "                           margins=True, margins_name='Total')\n",
    "#test chi square\n",
    "chisq_freq_3\n",
    "stats.chi2_contingency(chisq_freq_3)\n",
    "\n",
    "#not valid, no difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb27eb6",
   "metadata": {},
   "source": [
    "### Price and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq_freq_4 = pd.crosstab(dataset['price_sqrt_cat'].astype('category'), \n",
    "                           dataset['month_sold'].astype('category'), \n",
    "                           margins=True, margins_name='Total')\n",
    "#test chi square\n",
    "chisq_freq_4\n",
    "stats.chi2_contingency(chisq_freq_4)\n",
    "\n",
    "\n",
    "#valid relationship between price and month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f8ddf",
   "metadata": {},
   "source": [
    "## Check for Multicolinearity between Predictor Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ae33d",
   "metadata": {},
   "source": [
    "### Change sqft_sqrt to categorical bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut square foot living  into 6 bins\n",
    "dataset['sqft_sqrt_cat'] = pd.cut(dataset['sqft_sqrt'], 6)\n",
    "\n",
    "#check dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4d164",
   "metadata": {},
   "source": [
    "### Square feet and lattitude location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location and sqft_sqrt\n",
    "\n",
    "chisq_freq_5 = pd.crosstab(dataset['sqft_sqrt_cat'].astype('category'), \n",
    "                           dataset['lat_cat'].astype('category'), \n",
    "                           margins=True, margins_name='Total')\n",
    "#test chi square\n",
    "chisq_freq_5\n",
    "stats.chi2_contingency(chisq_freq_5)\n",
    "\n",
    "#valid relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21790b77",
   "metadata": {},
   "source": [
    "### Square feet and month sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqft_sqrt and month\n",
    "\n",
    "chisq_freq_6 = pd.crosstab(dataset['sqft_sqrt_cat'].astype('category'), \n",
    "                           dataset['month_sold'].astype('category'), \n",
    "                           margins=True, margins_name='Total')\n",
    "#test chi square\n",
    "chisq_freq_6\n",
    "stats.chi2_contingency(chisq_freq_6)\n",
    "\n",
    "#not valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193266ba",
   "metadata": {},
   "source": [
    "### Square feet and renovation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqft_sqrt and renovate\n",
    "\n",
    "chisq_freq_7 = pd.crosstab(dataset['sqft_sqrt_cat'].astype('category'), \n",
    "                           dataset['renovate'].astype('category'), \n",
    "                           margins=True, margins_name='Total')\n",
    "#test chi square\n",
    "chisq_freq_7\n",
    "stats.chi2_contingency(chisq_freq_7)\n",
    "\n",
    "#not valid relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95e406",
   "metadata": {},
   "source": [
    "### Location category and month sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create frequency table\n",
    "#chisq_freq_8_a = pd.crosstab(dataset['loc_cat'], \n",
    "                           #dataset['month_sold'].astype('category'), \n",
    "                           #margins=True, margins_name='Total')\n",
    "#chisq_freq_8_a\n",
    "\n",
    "#run chi square test\n",
    "#stats.chi2_contingency(chisq_freq_8_a)\n",
    "\n",
    "#not valid, expected values below 5\n",
    "\n",
    "\n",
    "chisq_freq_8_b = pd.crosstab(dataset['lat_cat'], \n",
    "                           dataset['month_sold'].astype('category'), \n",
    "                           margins=True, margins_name='Total')\n",
    "chisq_freq_8_b\n",
    "\n",
    "#run chi square test\n",
    "stats.chi2_contingency(chisq_freq_8_b)\n",
    "\n",
    "#VALID relationship\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc315b5",
   "metadata": {},
   "source": [
    "### Location category and renovate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f24a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create frequency table\n",
    "#chisq_freq_9_a = pd.crosstab(dataset['loc_cat'], \n",
    "                           #dataset['renovate'], \n",
    "                           #margins=True, margins_name='Total')\n",
    "#chisq_freq_9_a\n",
    "\n",
    "#run chi square test\n",
    "#stats.chi2_contingency(chisq_freq_9_a)\n",
    "\n",
    "#not valid, expected values below 5\n",
    "\n",
    "\n",
    "chisq_freq_9_b = pd.crosstab(dataset['lat_cat'], \n",
    "                           dataset['renovate'], \n",
    "                           margins=True, margins_name='Total')\n",
    "chisq_freq_9_b\n",
    "\n",
    "#run chi square test\n",
    "stats.chi2_contingency(chisq_freq_9_b)\n",
    "\n",
    "#VALID relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed4b4c9",
   "metadata": {},
   "source": [
    "###  Month sold and renovation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ffe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq_freq_10 = pd.crosstab(dataset['month_sold'], \n",
    "                           dataset['renovate'], \n",
    "                           margins=True, margins_name='Total')\n",
    "chisq_freq_10\n",
    "\n",
    "#run chi square test\n",
    "#stats.chi2_contingency(chisq_freq_10)\n",
    "\n",
    "#no relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597ecc0",
   "metadata": {},
   "source": [
    "## Based on associations tests, location is associated with multiple other variables which causes multicolinearity concerns. Since month is a predictor with 12 levels, it needs to be reduced into seasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4ee34",
   "metadata": {},
   "source": [
    "Update month sold into 4 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2d428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09347eaa",
   "metadata": {},
   "source": [
    "## 4. Data Modeling and Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439474d0",
   "metadata": {},
   "source": [
    "* Determine the need for a supervised or unsupervised learning method and identify dependent and independent variables\n",
    "* Train, test, and provide accuracy and evaluation metrics for model results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848e9ce",
   "metadata": {},
   "source": [
    "### The model for data requires a supervised learning method: multinomial linear regression.\n",
    "\n",
    "* The outcome variable is price (price_sqrt).\n",
    "* The predictor variables are : sqft_sqrt, month sold, and renovation status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fa92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ff640f",
   "metadata": {},
   "source": [
    "## Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25369b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['renovate_code'] = pd.to_numeric(dataset['renovate'].replace(['Yes', 'No'], [1, 0], inplace=True))\n",
    "#dataset.head(50)\n",
    "\n",
    "ren_dum = pd.get_dummies(dataset['renovate'], prefix = 'ren')\n",
    "ren_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a89265",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dum = pd.get_dummies(dataset['month_sold'], prefix = 'mon')\n",
    "month_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f49b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = pd.concat([dataset, month_dum, ren_dum], axis = 1)\n",
    "dataset_final.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f92415",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dtype(dataset_final['ren_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(dataset_final['mon_1'])\n",
    "\n",
    "#pd.to_numeric(dataset_final['mon_2'])\n",
    "#pd.to_numeric(dataset_final['mon_3'])\n",
    "#pd.to_numeric(dataset_final['mon_4'])\n",
    "#pd.to_numeric(dataset_final['mon_5'])\n",
    "#pd.to_numeric(dataset_final['mon_6'])\n",
    "#pd.to_numeric(dataset_final['mon_7'])\n",
    "#pd.to_numeric(dataset_final['mon_8'])\n",
    "#pd.to_numeric(dataset_final['mon_9'])\n",
    "#pd.to_numeric(dataset_final['mon_10'])\n",
    "#pd.to_numeric(dataset_final['mon_11'])\n",
    "#pd.to_numeric(dataset_final['mon_12'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dtype(dataset_final['mon_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d7fe6",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9f313",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7d884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea6f121",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = (dataset_final[['sqft_sqrt']])\n",
    "#'ren_1', 'ren_2'\n",
    "#'mon_1','mon_2','mon_3','mon_4','mon_5','mon_6','mon_7','mon_8','mon_9','mon_10','mon_11','mon_12']]\n",
    "y = pd.array(dataset_final['price_sqrt'])\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c18172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b0ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e614940",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e737c",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d0d3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
